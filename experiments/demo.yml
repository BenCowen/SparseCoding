#"""
#Configuration file template.
#
#@author Benjamin Cowen
#@date 7 Feb 2022
#@contact benjamin.cowen.math@gmail.com
#"""

# Experiment settings
experiment-name: celeb-dict-train
save-dir: "K:\\SparseCoding\\SCRATCH\\celeb-dict-sgd4"
device: "cuda:0"
allow-continuation: True
seed-config:
  torch-seed: 2322
  numpy-seed: 2223

# Dataset
data-config:
  class: PyTorchDataset
  module: lib.data_loaders.pytorch_datasets
  data-dir: "K:\\DATASETS\\celeba"
  n-loader-workers: 4
  # TODO: windowing might be pointless... focus on loss fcn applied to recon
  image-size: 128
  batch-size: 64
  custom-transforms:
    OverlappingPatches:
      patch-size: 32
      overlap-percentage: 0.25
      vectorize: True

model-config:
  class: Dictionary
  module: lib.model_blocks.dictionary
  code-len: 256

trainer-config:
  class: DictionaryLearning
  module: lib.trainers.dictionary_learning
  max-epoch: 1000
  batches-per-epoch: 99999999999 # Cut out early
  prints-per-epoch: 5
  loss-config:
    recon-loss:
#      SSIM:
#        kernel-size: 18
#        sigma: 1.5
      MSELoss: {}
#      TV: {}
#    code-loss: Q
#      L1: {}
  optimizer-config:
    class: SGD
    kwargs:
      lr: 0.005
      momentum: 0.9
      nesterov: True
    scheduler-config:
      class: StepLR
      step-size: 10
      kwargs:
        gamma: 0.99
  encoder-config:
    class: FISTA
    module: lib.model_blocks.ISTA
    n-iters: 10
    sparsity-weight: 0.5